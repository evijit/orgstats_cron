name: Daily HF Models Data Update

on:
  schedule:
    - cron: '0 2 * * *'
  workflow_dispatch:

env:
  ACTIONS_RUNNER_DEBUG: true
  ACTIONS_STEP_DEBUG: true

jobs:
  update-data:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    strategy:
      fail-fast: false

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Log system resources (Initial)
      run: |
        echo "=== System Information ==="
        echo "CPU cores: $(nproc)"
        echo "Memory total: $(free -h | grep 'Mem:' | awk '{print $2}')"
        echo "Memory available: $(free -h | grep 'Mem:' | awk '{print $7}')"
        echo "Disk space: $(df -h / | tail -1 | awk '{print $4}')"
        echo "Swap: $(free -h | grep 'Swap:' | awk '{print $2}')"
        echo "Python version: $(python --version)"
        echo "Pip packages:"
        pip list | grep -E "(pandas|psutil|duckdb)" || echo "Some packages not found"
        echo "=========================="

    - name: Clean up previous runs
      run: |
        echo "üßπ Cleaning up any previous temporary files..."
        rm -f models_processed.parquet.tmp 2>/dev/null || true
        rm -f *.tmp 2>/dev/null || true
        rm -f models_processed.parquet 2>/dev/null || true
        echo "‚úÖ Cleanup completed"

    - name: Run preprocessing (Attempt 1)
      id: preprocess_1
      continue-on-error: true
      env:
        HF_TOKEN: ${{ secrets.HF_TOKEN }}
      run: |
        echo "üîÑ Starting preprocessing attempt 1/3..."
        echo "=== Memory before processing ==="
        free -h
        echo "=== Disk space before processing ==="
        df -h
        echo "=== Starting preprocessing ==="
        timeout 2400s python preprocess.py
        echo "‚úÖ Preprocessing attempt 1 completed successfully"

    - name: Check preprocessing result (Attempt 1)
      id: check_1
      if: steps.preprocess_1.outcome == 'success'
      run: |
        if [ -f "models_processed.parquet" ]; then
          file_size=$(stat -c%s "models_processed.parquet")
          echo "‚úÖ Preprocessing successful on attempt 1"
          echo "üìä Output file size: ${file_size} bytes"
          echo "success=true" >> $GITHUB_OUTPUT
        else
          echo "‚ùå Preprocessing failed - no output file"
          echo "success=false" >> $GITHUB_OUTPUT
        fi

    - name: Log system state after attempt 1
      if: steps.preprocess_1.outcome == 'failure'
      run: |
        echo "=== System state after failed attempt 1 ==="
        echo "Memory usage:"
        free -h
        echo "Disk usage:"
        df -h
        echo "Process list:"
        ps aux | head -10
        echo "Cleaning up before retry..."
        rm -f models_processed.parquet.tmp 2>/dev/null || true
        rm -f *.tmp 2>/dev/null || true

    - name: Wait before retry (Attempt 1 failed)
      if: steps.preprocess_1.outcome == 'failure'
      run: |
        echo "‚è≥ Waiting 60 seconds before attempt 2..."
        sleep 60

    - name: Run preprocessing (Attempt 2)
      id: preprocess_2
      if: steps.preprocess_1.outcome == 'failure'
      continue-on-error: true
      env:
        HF_TOKEN: ${{ secrets.HF_TOKEN }}
      run: |
        echo "üîÑ Starting preprocessing attempt 2/3..."
        echo "=== Memory before processing ==="
        free -h
        echo "=== Disk space before processing ==="
        df -h
        echo "=== Starting preprocessing ==="
        timeout 2400s python preprocess.py
        echo "‚úÖ Preprocessing attempt 2 completed successfully"

    - name: Check preprocessing result (Attempt 2)
      id: check_2
      if: steps.preprocess_2.outcome == 'success'
      run: |
        if [ -f "models_processed.parquet" ]; then
          file_size=$(stat -c%s "models_processed.parquet")
          echo "‚úÖ Preprocessing successful on attempt 2"
          echo "üìä Output file size: ${file_size} bytes"
          echo "success=true" >> $GITHUB_OUTPUT
        else
          echo "‚ùå Preprocessing failed - no output file"
          echo "success=false" >> $GITHUB_OUTPUT
        fi

    - name: Log system state after attempt 2
      if: steps.preprocess_2.outcome == 'failure'
      run: |
        echo "=== System state after failed attempt 2 ==="
        echo "Memory usage:"
        free -h
        echo "Disk usage:"
        df -h
        echo "Process list:"
        ps aux | head -10
        echo "Cleaning up before final retry..."
        rm -f models_processed.parquet.tmp 2>/dev/null || true
        rm -f *.tmp 2>/dev/null || true

    - name: Wait before final retry (Attempt 2 failed)
      if: steps.preprocess_2.outcome == 'failure'
      run: |
        echo "‚è≥ Waiting 60 seconds before final attempt..."
        sleep 60

    - name: Run preprocessing (Attempt 3 - Final)
      id: preprocess_3
      if: steps.preprocess_1.outcome == 'failure' && steps.preprocess_2.outcome == 'failure'
      env:
        HF_TOKEN: ${{ secrets.HF_TOKEN }}
      run: |
        echo "üîÑ Starting preprocessing attempt 3/3 (FINAL)..."
        echo "=== Memory before processing ==="
        free -h
        echo "=== Disk space before processing ==="
        df -h
        echo "=== Starting preprocessing ==="
        timeout 2400s python preprocess.py
        echo "‚úÖ Preprocessing attempt 3 completed successfully"

    - name: Check preprocessing result (Final)
      id: check_final
      if: steps.preprocess_3.outcome == 'success'
      run: |
        if [ -f "models_processed.parquet" ]; then
          file_size=$(stat -c%s "models_processed.parquet")
          echo "‚úÖ Preprocessing successful on final attempt"
          echo "üìä Output file size: ${file_size} bytes"
          echo "success=true" >> $GITHUB_OUTPUT
        else
          echo "‚ùå All preprocessing attempts failed - no output file"
          echo "success=false" >> $GITHUB_OUTPUT
          exit 1
        fi

    - name: Determine overall preprocessing success
      id: preprocessing_status
      run: |
        if [[ "${{ steps.check_1.outputs.success }}" == "true" ]] || \
           [[ "${{ steps.check_2.outputs.success }}" == "true" ]] || \
           [[ "${{ steps.check_final.outputs.success }}" == "true" ]]; then
          echo "‚úÖ Preprocessing completed successfully"
          echo "success=true" >> $GITHUB_OUTPUT
        else
          echo "‚ùå All preprocessing attempts failed"
          echo "success=false" >> $GITHUB_OUTPUT
          exit 1
        fi

    - name: Detailed file validation
      id: validate_output
      if: steps.preprocessing_status.outputs.success == 'true'
      run: |
        echo "=== Detailed Output Validation ==="
        if [ -f "models_processed.parquet" ]; then
          file_size=$(stat -c%s "models_processed.parquet")
          file_size_mb=$((file_size / 1024 / 1024))
          echo "‚úÖ File exists: models_processed.parquet"
          echo "üìä File size: ${file_size} bytes (${file_size_mb} MB)"
          
          if [ $file_size -gt 1048576 ]; then
            echo "‚úÖ File size looks reasonable (> 1MB)"
          else
            echo "‚ùå File size too small (${file_size_mb} MB), might be corrupted"
            exit 1
          fi
        else
          echo "‚ùå Output file does not exist"
          exit 1
        fi

    - name: Python data validation
      id: python_validation
      if: steps.preprocessing_status.outputs.success == 'true'
      run: |
        echo "üîç Running Python validation..."
        python - <<EOF
        import pandas as pd
        import sys
        import traceback
        
        try:
            print('üìä Loading parquet file for validation...')
            df = pd.read_parquet('models_processed.parquet')
            print('‚úÖ File loaded successfully')
            print(f'   - Rows: {len(df):,}')
            print(f'   - Columns: {len(df.columns)}')
            print(f'   - Memory usage: {df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB')
            
            # Check for expected columns
            required_cols = ['id', 'downloads', 'likes', 'params', 'organization', 'has_robot']
            missing_cols = [col for col in required_cols if col not in df.columns]
            
            if missing_cols:
                print(f'‚ö†Ô∏è Warning: Missing columns: {missing_cols}')
            else:
                print('‚úÖ All essential columns present')
            
            # Data quality checks
            print('üîç Data quality checks:')
            print(f'   - Null values in id column: {df["id"].isnull().sum()}')
            print(f'   - Duplicate ids: {df["id"].duplicated().sum()}')
            
            if 'has_robot' in df.columns:
                robot_count = df['has_robot'].sum()
                print(f'   - Models with robotics tags: {robot_count:,}')
                
                # Show some examples if they exist
                if robot_count > 0:
                    print('   - Sample robotics models:')
                    robotics_sample = df[df['has_robot']].head(3)
                    for _, row in robotics_sample.iterrows():
                        print(f'     ‚Ä¢ {row["id"]}')
            
            if 'organization' in df.columns:
                org_count = df['organization'].nunique()
                print(f'   - Unique organizations: {org_count:,}')
                
                # Show top organizations
                top_orgs = df['organization'].value_counts().head(5)
                print('   - Top 5 organizations:')
                for org, count in top_orgs.items():
                    print(f'     ‚Ä¢ {org}: {count:,} models')
            
            if 'params' in df.columns:
                param_stats = df['params'].describe()
                print(f'   - Model size stats (GB):')
                print(f'     ‚Ä¢ Mean: {param_stats["mean"]:.2f}')
                print(f'     ‚Ä¢ Median: {param_stats["50%"]:.2f}')
                print(f'     ‚Ä¢ Max: {param_stats["max"]:.2f}')
            
            if len(df) > 0:
                print('‚úÖ Data validation passed')
                print(f'üìä Total models processed: {len(df):,}')
            else:
                print('‚ùå No data in file')
                sys.exit(1)
                
        except Exception as e:
            print(f'‚ùå Data validation failed: {str(e)}')
            traceback.print_exc()
            sys.exit(1)
        EOF

    - name: Upload to Hugging Face (Attempt 1)
      id: upload_1
      if: steps.preprocessing_status.outputs.success == 'true'
      continue-on-error: true
      env:
        HF_TOKEN: ${{ secrets.HF_TOKEN }}
      run: |
        echo "üì§ Starting upload attempt 1/3..."
        python - <<EOF
        from huggingface_hub import HfApi
        import os
        from datetime import datetime
        import sys
        
        try:
            api = HfApi()
            timestamp = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')
            print(f'üì§ Uploading to evijit/OrgStats at {timestamp}')
            
            result = api.upload_file(
                path_or_fileobj='models_processed.parquet',
                path_in_repo='models_processed.parquet',
                repo_id='evijit/OrgStats',
                repo_type='space',
                token=os.environ['HF_TOKEN'],
                commit_message=f'Update models data - {timestamp}'
            )
            print(f'‚úÖ Upload attempt 1 successful: {result}')
            
        except Exception as e:
            print(f'‚ùå Upload attempt 1 failed: {e}')
            import traceback
            traceback.print_exc()
            sys.exit(1)
        EOF

    - name: Upload to Hugging Face (Attempt 2)
      id: upload_2
      if: steps.preprocessing_status.outputs.success == 'true' && steps.upload_1.outcome == 'failure'
      continue-on-error: true
      env:
        HF_TOKEN: ${{ secrets.HF_TOKEN }}
      run: |
        echo "‚è≥ Waiting 30 seconds before upload retry..."
        sleep 30
        echo "üì§ Starting upload attempt 2/3..."
        python - <<EOF
        from huggingface_hub import HfApi
        import os
        from datetime import datetime
        import sys
        
        try:
            api = HfApi()
            timestamp = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')
            print(f'üì§ Uploading to evijit/OrgStats at {timestamp}')
            
            result = api.upload_file(
                path_or_fileobj='models_processed.parquet',
                path_in_repo='models_processed.parquet',
                repo_id='evijit/OrgStats',
                repo_type='space',
                token=os.environ['HF_TOKEN'],
                commit_message=f'Update models data - {timestamp} (retry 2)'
            )
            print(f'‚úÖ Upload attempt 2 successful: {result}')
            
        except Exception as e:
            print(f'‚ùå Upload attempt 2 failed: {e}')
            import traceback
            traceback.print_exc()
            sys.exit(1)
        EOF

    - name: Upload to Hugging Face (Attempt 3 - Final)
      id: upload_3
      if: steps.preprocessing_status.outputs.success == 'true' && steps.upload_1.outcome == 'failure' && steps.upload_2.outcome == 'failure'
      env:
        HF_TOKEN: ${{ secrets.HF_TOKEN }}
      run: |
        echo "‚è≥ Waiting 30 seconds before final upload attempt..."
        sleep 30
        echo "üì§ Starting upload attempt 3/3 (FINAL)..."
        python - <<EOF
        from huggingface_hub import HfApi
        import os
        from datetime import datetime
        import sys
        
        try:
            api = HfApi()
            timestamp = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')
            print(f'üì§ Uploading to evijit/OrgStats at {timestamp}')
            
            result = api.upload_file(
                path_or_fileobj='models_processed.parquet',
                path_in_repo='models_processed.parquet',
                repo_id='evijit/OrgStats',
                repo_type='space',
                token=os.environ['HF_TOKEN'],
                commit_message=f'Update models data - {timestamp} (final retry)'
            )
            print(f'‚úÖ Final upload attempt successful: {result}')
            
        except Exception as e:
            print(f'‚ùå All upload attempts failed: {e}')
            import traceback
            traceback.print_exc()
            sys.exit(1)
        EOF

    - name: Determine upload success
      id: upload_status
      if: steps.preprocessing_status.outputs.success == 'true'
      run: |
        if [[ "${{ steps.upload_1.outcome }}" == "success" ]] || \
           [[ "${{ steps.upload_2.outcome }}" == "success" ]] || \
           [[ "${{ steps.upload_3.outcome }}" == "success" ]]; then
          echo "‚úÖ Upload completed successfully"
          echo "success=true" >> $GITHUB_OUTPUT
        else
          echo "‚ùå All upload attempts failed"
          echo "success=false" >> $GITHUB_OUTPUT
        fi

    - name: Upload artifact as backup
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: models-processed-parquet-${{ github.run_number }}
        path: models_processed.parquet
        retention-days: 7

    - name: Final system metrics
      if: always()
      run: |
        echo "=== Final Performance Metrics ==="
        if [ -f "models_processed.parquet" ]; then
          file_size=$(stat -c%s "models_processed.parquet")
          file_size_mb=$((file_size / 1024 / 1024))
          echo "üìä Final output: ${file_size_mb} MB"
          ls -lh models_processed.parquet
        else
          echo "‚ùå No output file found"
        fi
        
        echo "=== Final System Resources ==="
        echo "Memory usage:"
        free -h
        echo "Disk usage:"
        df -h
        echo "=== Cleanup ==="
        rm -f *.tmp 2>/dev/null || true
        rm -f data_meta.txt 2>/dev/null || true

    - name: Workflow summary
      if: always()
      run: |
        echo "=== üéØ WORKFLOW SUMMARY ==="
        echo "‚è±Ô∏è Total execution time: $SECONDS seconds"
        
        # Preprocessing summary
        if [[ "${{ steps.preprocessing_status.outputs.success }}" == "true" ]]; then
          echo "‚úÖ SUCCESS: Data preprocessing completed"
          
          # Determine which attempt succeeded
          if [[ "${{ steps.check_1.outputs.success }}" == "true" ]]; then
            echo "   ‚Üí Succeeded on attempt 1"
          elif [[ "${{ steps.check_2.outputs.success }}" == "true" ]]; then
            echo "   ‚Üí Succeeded on attempt 2"
          elif [[ "${{ steps.check_final.outputs.success }}" == "true" ]]; then
            echo "   ‚Üí Succeeded on attempt 3"
          fi
        else
          echo "‚ùå FAILED: Data preprocessing failed after 3 attempts"
        fi
        
        # Upload summary
        if [[ "${{ steps.upload_status.outputs.success }}" == "true" ]]; then
          echo "‚úÖ SUCCESS: File uploaded to Hugging Face Space"
          
          # Determine which upload attempt succeeded
          if [[ "${{ steps.upload_1.outcome }}" == "success" ]]; then
            echo "   ‚Üí Upload succeeded on attempt 1"
          elif [[ "${{ steps.upload_2.outcome }}" == "success" ]]; then
            echo "   ‚Üí Upload succeeded on attempt 2"
          elif [[ "${{ steps.upload_3.outcome }}" == "success" ]]; then
            echo "   ‚Üí Upload succeeded on attempt 3"
          fi
        else
          echo "‚ùå FAILED: Upload to Hugging Face failed"
        fi
        
        # File info
        if [ -f "models_processed.parquet" ]; then
          echo "üìä Output file size: $(stat -c%s 'models_processed.parquet' | numfmt --to=iec)"
        fi
        
        echo "üéâ Workflow execution completed!"