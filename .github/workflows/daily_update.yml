name: Daily HF Models Data Update (Modular)

on:
  schedule:
    - cron: '0 2 * * *'  # Run at 2 AM UTC daily
  workflow_dispatch:

env:
  ACTIONS_RUNNER_DEBUG: true
  ACTIONS_STEP_DEBUG: true

jobs:
  update-data:
    runs-on: ubuntu-latest
    timeout-minutes: 90
    strategy:
      fail-fast: false

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    # --- NEW, FAST TESTING STEP ---
    # This step runs the entire pipeline logic on a small subset of data.
    # It provides fast feedback and validation before the main job.
    - name: Test pipeline logic on a small data subset
      env:
        TEST_DATA_LIMIT: 5000 # Fetch only 5000 rows for the test
      run: |
        echo "ðŸ§ª Running fast integration test on a small subset of data..."
        python test_pipeline.py
        echo "âœ… Pipeline logic test passed!"

    # --- MAIN PROCESSING STEP ---
    # This step runs on the full dataset only after the fast test passes.
    - name: Run main processing pipeline (full dataset)
      env:
        HF_TOKEN: ${{ secrets.HF_TOKEN }}
      run: |
        echo "=== Starting Main Data Processing Pipeline (Full Dataset) ==="
        echo "Start time: $(date -u '+%Y-%m-%d %H:%M:%S UTC')"

        # Function to run the main pipeline with timeout and monitoring
        run_main_pipeline() {
          local attempt=$1
          echo ""
          echo "ðŸ”„ Pipeline Execution (Attempt $attempt)"
          echo "======================================"
          # Run with timeout and capture output, returning the python script's exit code
          timeout 3600s python -u main.py 2>&1 | while IFS= read -r line; do
            echo "$(date -u '+%H:%M:%S'): $line"
          done
          return ${PIPESTATUS[0]}
        }

        # Execute pipeline with retry logic
        max_attempts=2
        attempt=1
        while [ $attempt -le $max_attempts ]; do
          echo "ðŸš€ Starting pipeline attempt $attempt of $max_attempts"
          if run_main_pipeline $attempt; then
            echo "âœ… Pipeline completed successfully on attempt $attempt!"
            echo "Completion time: $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
            break
          else
            exit_code=$?
            echo "âŒ Pipeline failed on attempt $attempt (exit code: $exit_code)"
            if [ $attempt -eq $max_attempts ]; then
              echo "ðŸ’¥ All pipeline attempts exhausted"
              exit $exit_code
            else
              echo "â³ Preparing for retry..."
              sleep 60
              attempt=$((attempt + 1))
            fi
          fi
        done

    - name: Detailed output verification
      id: detailed_verification
      run: |
        echo "=== Detailed Output Verification ==="
        if [ ! -f "models_processed.parquet" ]; then
          echo "âŒ Output file missing"
          echo "has_changes=false" >> $GITHUB_OUTPUT
          exit 1
        fi
        
        file_size_mb=$(($(stat -c%s "models_processed.parquet") / 1024 / 1024))
        echo "âœ… Output file exists: models_processed.parquet (${file_size_mb} MB)"

        if [ $file_size_mb -lt 2 ]; then
          echo "âŒ File size too small (${file_size_mb} MB)"
          echo "has_changes=false" >> $GITHUB_OUTPUT
          exit 1
        fi

        # Comprehensive validation script
        validation_result=$(python - <<EOF
        import pandas as pd, sys
        try:
            print('--- Comprehensive Validation ---')
            df = pd.read_parquet('models_processed.parquet')
            print(f'ðŸ“Š Shape: {df.shape}')
            
            expected_cols = ['id', 'downloads', 'likes', 'params', 'organization', 'has_robot', 'size_category']
            missing = [col for col in expected_cols if col not in df.columns]
            if missing:
                raise AssertionError(f"Missing critical columns: {missing}")
            print('âœ… All critical columns present.')
            
            if len(df) < 100000:
                print(f"âš ï¸  Dataset smaller than expected: {len(df):,} rows")
            else:
                print(f'âœ… Dataset size acceptable: {len(df):,} rows.')
            
            print('ðŸŽ‰ Validation successful!')
        except Exception as e:
            print(f'âŒ Validation failed: {e}', file=sys.stderr)
            import traceback
            traceback.print_exc()
            sys.exit(1)
        EOF
        )

        validation_exit_code=$?
        echo "${validation_result}"
        if [ $validation_exit_code -eq 0 ]; then
          echo "has_changes=true" >> $GITHUB_OUTPUT
          echo "file_size_mb=${file_size_mb}" >> $GITHUB_OUTPUT
        else
          echo "has_changes=false" >> $GITHUB_OUTPUT
          exit 1
        fi

    - name: Upload to Hugging Face Space
      if: steps.detailed_verification.outputs.has_changes == 'true'
      env:
        HF_TOKEN: ${{ secrets.HF_TOKEN }}
      run: |
        echo "=== Uploading to Hugging Face Space ==="
        python - <<EOF
        from huggingface_hub import HfApi
        import os, sys, time
        
        for attempt in range(3):
            try:
                print(f"ðŸ“¤ Upload attempt {attempt + 1}...")
                api = HfApi()
                api.upload_file(
                    path_or_fileobj='models_processed.parquet',
                    path_in_repo='models_processed.parquet',
                    repo_id='evijit/OrgStats',
                    repo_type='space',
                    token=os.environ['HF_TOKEN'],
                    commit_message=f'Automated data update - {time.strftime("%Y-%m-%d %H:%M:%S UTC")}'
                )
                print('âœ… Upload successful!')
                sys.exit(0)
            except Exception as e:
                print(f"âŒ Upload attempt {attempt + 1} failed: {e}")
                if attempt < 2:
                    print("Retrying in 45 seconds...")
                    time.sleep(45)
                else:
                    sys.exit(1)
        EOF

    - name: Create workflow summary
      if: always()
      run: |
        if [[ "${{ job.status }}" == "success" ]]; then
          echo "### ðŸŽ‰ SUCCESS: Data Processing Completed" >> $GITHUB_STEP_SUMMARY
          echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| ðŸ“Š Output File Size | ${{ steps.detailed_verification.outputs.file_size_mb }} MB |" >> $GITHUB_STEP_SUMMARY
          echo "| â±ï¸ Total Execution Time | $SECONDS seconds |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "âœ… **Data successfully uploaded to Hugging Face Space: evijit/OrgStats**" >> $GITHUB_STEP_SUMMARY
        else
          echo "### âŒ FAILURE: Data Processing Failed" >> $GITHUB_STEP_SUMMARY
          echo "The data processing pipeline did not complete successfully." >> $GITHUB_STEP_SUMMARY
          echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| â±ï¸ Failed After | $SECONDS seconds |" >> $GITHUB_STEP_SUMMARY
        fi
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "*Run [#${{ github.run_number }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})*" >> $GITHUB_STEP_SUMMARY

    - name: Upload build artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: pipeline-outputs-${{ github.run_number }}
        path: models_processed.parquet
        retention-days: 7
        if-no-files-found: warn