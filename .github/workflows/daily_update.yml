name: Daily HF Models Data Update

on:
  schedule:
    - cron: '0 2 * * *'
  workflow_dispatch:

env:
  ACTIONS_RUNNER_DEBUG: true
  ACTIONS_STEP_DEBUG: true

jobs:
  update-data:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    strategy:
      fail-fast: false

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Log system resources
      run: |
        echo "=== System Information ==="
        echo "CPU cores: $(nproc)"
        echo "Memory total: $(free -h | grep 'Mem:' | awk '{print $2}')"
        echo "Memory available: $(free -h | grep 'Mem:' | awk '{print $7}')"
        echo "Disk space: $(df -h / | tail -1 | awk '{print $4}')"
        echo "Swap: $(free -h | grep 'Swap:' | awk '{print $2}')"
        echo "Python version: $(python --version)"
        echo "Pip packages:"
        pip list | grep -E "(pandas|psutil|duckdb)" || echo "Some packages not found"
        echo "=========================="

    - name: Run preprocessing with retries
      env:
        HF_TOKEN: ${{ secrets.HF_TOKEN }}
      run: |
        echo "Starting data preprocessing with retry logic..."
        run_preprocessing() {
          local attempt=$1
          echo "=== Preprocessing Attempt $attempt ==="
          timeout 2400s python preprocess.py
          return $?
        }
        max_attempts=3
        attempt=1
        while [ $attempt -le $max_attempts ]; do
          echo "üîÑ Running preprocessing (attempt $attempt/$max_attempts)"
          if run_preprocessing $attempt; then
            echo "‚úÖ Preprocessing completed successfully on attempt $attempt"
            break
          else
            exit_code=$?
            echo "‚ùå Preprocessing failed on attempt $attempt (exit code: $exit_code)"
            if [ $attempt -eq $max_attempts ]; then
              echo "üí• All preprocessing attempts failed"
              exit $exit_code
            else
              echo "‚è≥ Waiting 60 seconds before retry..."
              sleep 60
              rm -f models_processed.parquet.tmp 2>/dev/null || true
              rm -f *.tmp 2>/dev/null || true
              echo "System state before retry:"
              free -h
              df -h
              attempt=$((attempt + 1))
            fi
          fi
        done

    - name: Verify and validate output
      id: check_output
      run: |
        echo "=== Output Verification ==="
        if [ -f "models_processed.parquet" ]; then
          file_size=$(stat -c%s "models_processed.parquet")
          file_size_mb=$((file_size / 1024 / 1024))
          echo "‚úÖ File exists: models_processed.parquet"
          echo "üìä File size: ${file_size} bytes (${file_size_mb} MB)"
          if [ $file_size -gt 1048576 ]; then
            echo "‚úÖ File size looks reasonable"
            python -c "
import pandas as pd
import sys
try:
    print('üîç Validating parquet file...')
    df = pd.read_parquet('models_processed.parquet')
    print('‚úÖ File validation successful:')
    print('   - Rows: {:,}'.format(len(df)))
    print('   - Columns: {}'.format(len(df.columns)))
    print('   - Column names: {}'.format(list(df.columns)))

    required_cols = ['id', 'downloads', 'likes']
    missing_cols = [col for col in required_cols if col not in df.columns]
    if missing_cols:
        print('‚ö†Ô∏è Warning: Missing columns: {}'.format(missing_cols))
    else:
        print('‚úÖ All essential columns present')

    if len(df) > 0:
        print('‚úÖ Data validation passed')
    else:
        print('‚ùå No data in file')
        sys.exit(1)

except Exception as e:
    print('‚ùå File validation failed: {}'.format(str(e)))
    sys.exit(1)
"
            if [ $? -eq 0 ]; then
              echo "has_changes=true" >> $GITHUB_OUTPUT
            else
              echo "‚ùå File validation failed"
              echo "has_changes=false" >> $GITHUB_OUTPUT
              exit 1
            fi
          else
            echo "‚ùå File size too small (${file_size_mb} MB), might be corrupted"
            echo "has_changes=false" >> $GITHUB_OUTPUT
            exit 1
          fi
        else
          echo "‚ùå Output file does not exist"
          echo "has_changes=false" >> $GITHUB_OUTPUT
          exit 1
        fi

    - name: Upload to Hugging Face Space with retries
      if: steps.check_output.outputs.has_changes == 'true'
      run: |
        echo "=== Uploading to Hugging Face Space ==="
        upload_to_hf() {
          local attempt=$1
          echo "üîÑ Upload attempt $attempt"
          python -c "
from huggingface_hub import HfApi
import os
from datetime import datetime
import sys
try:
    api = HfApi()
    timestamp = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')
    print(f'üì§ Uploading to evijit/OrgStats at {timestamp}')
    result = api.upload_file(
        path_or_fileobj='models_processed.parquet',
        path_in_repo='models_processed.parquet',
        repo_id='evijit/OrgStats',
        repo_type='space',
        token=os.environ['HF_TOKEN'],
        commit_message=f'Update models data - {timestamp}'
    )
    print(f'‚úÖ Successfully uploaded to: {result}')
except Exception as e:
    print(f'‚ùå Upload failed: {e}')
    import traceback
    traceback.print_exc()
    sys.exit(1)
"
          return $?
        }
        max_upload_attempts=3
        upload_attempt=1
        while [ $upload_attempt -le $max_upload_attempts ]; do
          echo "=== Upload Attempt $upload_attempt/$max_upload_attempts ==="
          if upload_to_hf $upload_attempt; then
            echo "‚úÖ Upload completed successfully on attempt $upload_attempt"
            break
          else
            exit_code=$?
            echo "‚ùå Upload failed on attempt $upload_attempt"
            if [ $upload_attempt -eq $max_upload_attempts ]; then
              echo "üí• All upload attempts failed"
              exit $exit_code
            else
              echo "‚è≥ Waiting 30 seconds before retry..."
              sleep 30
              upload_attempt=$((upload_attempt + 1))
            fi
          fi
        done

    - name: Upload artifact as backup
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: models-processed-parquet-${{ github.run_number }}
        path: models_processed.parquet
        retention-days: 7

    - name: Performance metrics and cleanup
      if: always()
      run: |
        echo "=== Performance Metrics ==="
        if [ -f "models_processed.parquet" ]; then
          file_size=$(stat -c%s "models_processed.parquet")
          file_size_mb=$((file_size / 1024 / 1024))
          echo "üìä Final output: ${file_size_mb} MB"
          ls -lh models_processed.parquet
        else
          echo "‚ùå No output file found"
        fi
        echo "=== System Resources (Final) ==="
        free -h
        df -h
        echo "=== Cleanup ==="
        rm -f *.tmp 2>/dev/null || true
        rm -f data_meta.txt 2>/dev/null || true
        echo "üéâ Workflow execution completed!"

    - name: Workflow summary
      if: always()
      run: |
        echo "=== Workflow Summary ==="
        if [ -f "models_processed.parquet" ]; then
          echo "‚úÖ SUCCESS: Data processing completed"
          echo "‚úÖ SUCCESS: File uploaded to Hugging Face Space"
          echo "üìä Output file size: $(stat -c%s 'models_processed.parquet' | numfmt --to=iec)"
        else
          echo "‚ùå FAILED: Data processing did not complete successfully"
        fi
        echo "‚è±Ô∏è Total workflow execution time: $SECONDS seconds"
