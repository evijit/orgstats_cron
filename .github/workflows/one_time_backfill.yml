name: One-Time Hub Snapshots Backfill with Verification

on:
  workflow_dispatch:
    inputs:
      start_date:
        description: 'Backfill Start Date (YYYY-MM-DD)'
        required: true
        default: '2025-05-28'
      end_date:
        description: 'Backfill End Date (YYYY-MM-DD)'
        required: true
        default: '2025-07-02'

jobs:
  backfill_snapshots:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout workflow repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          pip install huggingface_hub
          sudo apt-get update
          sudo apt-get install -y git-lfs
          git lfs install

      - name: Clone target repo without downloading LFS files
        run: |
          GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/datasets/hfmlsoc/hub_weekly_snapshots target_repo

      - name: Run backfill snapshot generation
        run: |
          python hub_download.py ./target_repo --backfill-start-date ${{ github.event.inputs.start_date }} --backfill-end-date ${{ github.event.inputs.end_date }}

      - name: Verify Snapshot Integrity
        working-directory: ./target_repo
        run: |
          ITEM_TO_CHECK="models"
          START_DATE_STR="${{ github.event.inputs.start_date }}"
          END_DATE_STR="${{ github.event.inputs.end_date }}"
          MIN_SIZE_BYTES=102400

          echo "--- Verifying snapshot integrity for '$ITEM_TO_CHECK' from $START_DATE_STR to $END_DATE_STR ---"

          # Use a bash array to reliably store file paths
          declare -a file_paths_to_check=()
          
          current_date_ts=$(date -d "$START_DATE_STR" +%s)
          end_date_ts=$(date -d "$END_DATE_STR" +%s)

          while [ "$current_date_ts" -le "$end_date_ts" ]; do
            current_date_str=$(date -d "@$current_date_ts" +%Y-%m-%d)
            file_path="${ITEM_TO_CHECK}/${current_date_str}/${ITEM_TO_CHECK}.parquet"
            if [ -f "$file_path" ]; then
              # Add the found file path to the array
              file_paths_to_check+=("$file_path")
            fi
            # Move to the next week
            current_date_ts=$(date -d "$current_date_str + 7 days" +%s)
          done

          # Check if the array is empty
          if [ ${#file_paths_to_check[@]} -eq 0 ]; then
            echo "Verification FAILED: No snapshot files found in the specified date range. Aborting."
            exit 1
          fi

          echo "Files to be verified:"
          # Print the array contents for logging
          printf "%s\n" "${file_paths_to_check[@]}"

          # Get file sizes by passing the array directly to stat. This is the robust fix.
          FILE_SIZES=$(stat -c %s "${file_paths_to_check[@]}")

          echo "Corresponding file sizes (in bytes):"
          echo "$FILE_SIZES"

          # 1. Check for LFS pointers (files that are too small)
          TINY_FILES_COUNT=0
          for size in $FILE_SIZES; do
            if [ "$size" -lt "$MIN_SIZE_BYTES" ]; then
              TINY_FILES_COUNT=$((TINY_FILES_COUNT + 1))
            fi
          done

          if [ "$TINY_FILES_COUNT" -gt 0 ]; then
            echo "---"
            echo "Verification FAILED: Found $TINY_FILES_COUNT file(s) smaller than $MIN_SIZE_BYTES bytes."
            echo "This indicates that some files are still Git LFS pointers. Aborting."
            echo "---"
            exit 1
          fi
          echo "Verification PASSED: All files are larger than the minimum threshold."

          # 2. Check if all file sizes are identical
          if [ ${#file_paths_to_check[@]} -gt 1 ]; then
            UNIQUE_SIZES_COUNT=$(echo "$FILE_SIZES" | sort -u | wc -l)
            if [ "$UNIQUE_SIZES_COUNT" -eq 1 ]; then
              echo "---"
              echo "Verification FAILED: All backfilled snapshot files have the exact same size."
              echo "This indicates the data duplication issue was not resolved. Aborting."
              echo "---"
              exit 1
            fi
            echo "Verification PASSED: Snapshot file sizes are varied as expected."
          else
            echo "Only one snapshot file found in range, skipping uniqueness check."
          fi

          echo "---"
          echo "All verification checks passed. The backfill appears successful. Proceeding."
          echo "---"

      - name: Commit and push new snapshots
        working-directory: ./target_repo
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          
          git remote set-url origin https://huggingface-bot:${HF_TOKEN}@huggingface.co/datasets/hfmlsoc/hub_weekly_snapshots
          
          ITEM_TO_COMMIT="models"
          
          if git status --porcelain -- "$ITEM_TO_COMMIT" | grep -qE '^\?\?| M'; then
            echo "Backfilled snapshots found for $ITEM_TO_COMMIT. Preparing commit."
            
            git lfs track "${ITEM_TO_COMMIT}/**/*.parquet"
            git add .gitattributes
            git add "$ITEM_TO_COMMIT"
            
            COMMIT_MSG="fix(data): Backfill ${ITEM_TO_COMMIT} snapshots from ${{ github.event.inputs.start_date }} to ${{ github.event.inputs.end_date }}"
            git commit -m "$COMMIT_MSG"
            
            echo "Pushing commit for $ITEM_TO_COMMIT"
            git push
          else
            echo "No new changes detected in the $ITEM_TO_COMMIT directory to push."
          fi